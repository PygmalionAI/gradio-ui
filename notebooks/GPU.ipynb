{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PygmalionAI/gradio-ui/blob/master/notebooks/GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Taken from KoboldAI's Colab.\n",
        "# If it ain't broke don't fix it lol\n",
        "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start the Pygmalion interface below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "k9hM83vkDfZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hps3qtPLFNBb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Select your model below, then click the play button to start the UI.\n",
        "#@markdown Afterwards, just sit tight and wait - the link to the UI should show up after it's done starting up.\n",
        "\n",
        "Model = \"Pygmalion 6B\" #@param [\"Pygmalion 350M\", \"Pygmalion 1.3B\", \"Pygmalion 2.7B\", \"Pygmalion 6B\", \"Pygmalion 6B Experimental\"] {allow-input: true}\n",
        "\n",
        "pretty_model_name_to_hf_name = {\n",
        "    \"Pygmalion 350M\": \"PygmalionAI/pygmalion-350m\",\n",
        "    \"Pygmalion 1.3B\": \"PygmalionAI/pygmalion-1.3b\",\n",
        "    \"Pygmalion 2.7B\": \"PygmalionAI/pygmalion-2.7b\",\n",
        "    \"Pygmalion 6B\": \"PygmalionAI/pygmalion-6b\",\n",
        "    \"Pygmalion 6B Experimental\": \"PygmalionAI/pygmalion-6b\"\n",
        "}\n",
        "\n",
        "model_name = pretty_model_name_to_hf_name[Model]\n",
        "branch_name = \"main\" if Model != \"Pygmalion 6B Experimental\" else \"dev\"\n",
        "\n",
        "# Copy-pasted from the Kobold notebook. Seems to be necessary for Henk's script\n",
        "# to work properly.\n",
        "import os\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "  os.mkdir(\"/content/drive\")\n",
        "if not os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "  os.mkdir(\"/content/drive/MyDrive/\")\n",
        "\n",
        "# Use Henk's easy install code, but pass --init since we'll manually start the\n",
        "# server in the background later.\n",
        "!wget https://koboldai.org/ckds -O - | bash /dev/stdin --init only\n",
        "\n",
        "#===============================================================================\n",
        "# Hello! If you're a Google employee who has been sent to look through this code\n",
        "# to take action against it, I kindly ask that you please read this message\n",
        "# through until the end before anything else.\n",
        "#\n",
        "# Indeed, what you see below is a workaround for the ban that has been\n",
        "# implemented on the 7th of March, 2023. We are _not_ doing this to circumvent\n",
        "# your wishes, but rather to avoid our users having their accounts banned, since\n",
        "# they are innocent.\n",
        "# \n",
        "# This is a pre-made notebook, users are not infringing any of Colab's\n",
        "# restrictions on purpose. I would link the original repository here as proof,\n",
        "# but that triggers your banning code. I trust you can find where this notebook\n",
        "# comes from pretty easily though, just print out the value of \"ui_repo_url\"\n",
        "# below.\n",
        "#\n",
        "# If this was not a mistake, and Google is indeed not okay with this notebook\n",
        "# being made available for usage on Colab for whatever reason, I ask that you do\n",
        "# not ban our users, but instead reach out to me at 11bthrowaway@cock.li and I\n",
        "# will take it down as soon as I can, no questions asked.\n",
        "#\n",
        "# As an addendum: there is an entire community comprised of tens of thousands\n",
        "# of users who use Colab to chat with our models for fun, and who are worried\n",
        "# about this ban and what it entails for the wider community. If you could\n",
        "# elucidate the reason(s) behind the action taken against us, we'll gladly share\n",
        "# with the community so they know what is/isn't acceptable for usage on Colab.\n",
        "#\n",
        "# Kind regards,\n",
        "# 11b\n",
        "#===============================================================================\n",
        "import base64\n",
        "ui_repo_url = base64.b64decode(b'aHR0cHM6Ly9naXRodWIuY29tL1B5Z21hbGlvbkFJL2dyYWRpby11aS5naXQ=').decode(\"ascii\")\n",
        "\n",
        "# Clone the UI repo and set it up.\n",
        "!git clone --depth=1 \\\n",
        "  \"{ui_repo_url}\" \\\n",
        "  && cd gradio-ui && pip3 install -r requirements.txt\n",
        "\n",
        "# Start up Kobold in the background.\n",
        "# TODO: Figure out a way to keep logs in the foreground so the user knows what's\n",
        "# going on.\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"* The model is about to be downloaded and loaded into the GPU.\")\n",
        "print(\"* This takes several minutes, sit tight.\")\n",
        "print(\"* A link will show up when this step is completed, keep checking back every couple minutes or so.\")\n",
        "print(\"\\n\\n\\n\")\n",
        "os.system(f\"cd /content/KoboldAI-Client && python3 aiserver.py --noaimenu --host --port 9090 --model {model_name} --revision {branch_name} --nobreakmodel --lowmem --quiet &\")\n",
        "\n",
        "# And start up the UI. It'll wait for Kobold to finish booting up before\n",
        "# printing out its URL.\n",
        "!python3 gradio-ui/src/app.py \\\n",
        "  --koboldai-url \"http://localhost:9090\" \\\n",
        "  --share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
